{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "72340ad8-060a-485a-9b30-ea03f88a8c96",
      "metadata": {
        "id": "72340ad8-060a-485a-9b30-ea03f88a8c96"
      },
      "source": [
        "## Imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bcfcd342-b811-4f41-8781-20cea08d08ce",
      "metadata": {
        "id": "bcfcd342-b811-4f41-8781-20cea08d08ce"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e8122bd-d86b-463e-ab56-2f92e7731939",
      "metadata": {
        "id": "7e8122bd-d86b-463e-ab56-2f92e7731939"
      },
      "source": [
        "## Data Preparation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f8cec10d-3658-4563-b203-be662f5cb4fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8cec10d-3658-4563-b203-be662f5cb4fc",
        "outputId": "5e291b41-d867-483c-cb51-bd2f43cfe1e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "x_train shape: (60000, 28, 28)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "864ae8a9-7b53-4287-b4a0-5a5d01952bf9",
      "metadata": {
        "tags": [],
        "id": "864ae8a9-7b53-4287-b4a0-5a5d01952bf9"
      },
      "source": [
        "## Try to build your own convolutional neural network in keras. Use 2D convolutional and max pooling layers for the first part of the network, use two of each. Use a flatten layer and a dropout layer before passing it to dense layer with softmax as output. Here is some documentation on these things that might help:\n",
        "\n",
        "* https://keras.io/api/layers/core_layers/input/\n",
        "* https://keras.io/api/layers/convolution_layers/convolution2d/\n",
        "* https://keras.io/api/layers/pooling_layers/max_pooling2d/\n",
        "* https://keras.io/api/layers/reshaping_layers/flatten/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3ffdde55-1d3f-4f72-9e91-bc9599d93e82",
      "metadata": {
        "id": "3ffdde55-1d3f-4f72-9e91-bc9599d93e82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56972fb5-6629-4bc0-cef8-b4ed64efdb89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 11, 11, 16)        4624      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 5, 5, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                4010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8954 (34.98 KB)\n",
            "Trainable params: 8954 (34.98 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size = (3,3), activation = 'relu'), #relu removes negative numbers\n",
        "        layers.MaxPooling2D((2,2)), #max pooling: subsampling\n",
        "        layers.Conv2D(16, kernel_size = (3,3), activation = 'relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation = 'softmax'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a357dfd6-ad6e-4eae-b1a6-ec4f25f850c8",
      "metadata": {
        "id": "a357dfd6-ad6e-4eae-b1a6-ec4f25f850c8"
      },
      "source": [
        "## Use the keras compile and fit functions to prepare and train your model.\n",
        "\n",
        "* https://keras.io/api/models/model_training_apis/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5e5cc9cf-63b2-4b93-9476-f237cf64f3c0",
      "metadata": {
        "id": "5e5cc9cf-63b2-4b93-9476-f237cf64f3c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e856e09-4e8f-451e-e027-566f08efda9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "211/211 [==============================] - 26s 121ms/step - loss: 2.2062 - accuracy: 0.2225 - val_loss: 2.1761 - val_accuracy: 0.3180\n",
            "Epoch 2/15\n",
            "211/211 [==============================] - 26s 122ms/step - loss: 2.1824 - accuracy: 0.2377 - val_loss: 2.1439 - val_accuracy: 0.3665\n",
            "Epoch 3/15\n",
            "211/211 [==============================] - 26s 122ms/step - loss: 2.1544 - accuracy: 0.2565 - val_loss: 2.1042 - val_accuracy: 0.4213\n",
            "Epoch 4/15\n",
            "211/211 [==============================] - 26s 122ms/step - loss: 2.1188 - accuracy: 0.2798 - val_loss: 2.0540 - val_accuracy: 0.4908\n",
            "Epoch 5/15\n",
            "211/211 [==============================] - 27s 128ms/step - loss: 2.0765 - accuracy: 0.3044 - val_loss: 1.9916 - val_accuracy: 0.5588\n",
            "Epoch 6/15\n",
            "211/211 [==============================] - 26s 123ms/step - loss: 2.0205 - accuracy: 0.3339 - val_loss: 1.9135 - val_accuracy: 0.6212\n",
            "Epoch 7/15\n",
            "211/211 [==============================] - 25s 117ms/step - loss: 1.9565 - accuracy: 0.3637 - val_loss: 1.8188 - val_accuracy: 0.6710\n",
            "Epoch 8/15\n",
            "211/211 [==============================] - 26s 124ms/step - loss: 1.8831 - accuracy: 0.3933 - val_loss: 1.7093 - val_accuracy: 0.7005\n",
            "Epoch 9/15\n",
            "211/211 [==============================] - 27s 126ms/step - loss: 1.8023 - accuracy: 0.4221 - val_loss: 1.5894 - val_accuracy: 0.7260\n",
            "Epoch 10/15\n",
            "211/211 [==============================] - 26s 125ms/step - loss: 1.7069 - accuracy: 0.4543 - val_loss: 1.4610 - val_accuracy: 0.7488\n",
            "Epoch 11/15\n",
            "211/211 [==============================] - 27s 127ms/step - loss: 1.6133 - accuracy: 0.4845 - val_loss: 1.3342 - val_accuracy: 0.7682\n",
            "Epoch 12/15\n",
            "211/211 [==============================] - 27s 126ms/step - loss: 1.5272 - accuracy: 0.5074 - val_loss: 1.2156 - val_accuracy: 0.7887\n",
            "Epoch 13/15\n",
            "211/211 [==============================] - 26s 122ms/step - loss: 1.4358 - accuracy: 0.5331 - val_loss: 1.1054 - val_accuracy: 0.8055\n",
            "Epoch 14/15\n",
            "211/211 [==============================] - 26s 125ms/step - loss: 1.3480 - accuracy: 0.5614 - val_loss: 1.0052 - val_accuracy: 0.8237\n",
            "Epoch 15/15\n",
            "211/211 [==============================] - 26s 122ms/step - loss: 1.2741 - accuracy: 0.5859 - val_loss: 0.9181 - val_accuracy: 0.8378\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d0fddddb9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Compile and fit here\n",
        "opt = keras.optimizers.SGD(learning_rate = 0.001)\n",
        "model.compile(optimizer = opt, loss= 'categorical_crossentropy', metrics = [\"accuracy\"])\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=15, batch_size = 256,\n",
        "    validation_split = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fc651e2-f302-4f13-8d4c-de93b4a2b51f",
      "metadata": {
        "id": "8fc651e2-f302-4f13-8d4c-de93b4a2b51f"
      },
      "source": [
        "## Use the keras Model evaluate function with our test data to evaluate its preformance. Print the test loss and test accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "24e3bb54-2c9c-4531-b9f6-dd3c2cf5310a",
      "metadata": {
        "id": "24e3bb54-2c9c-4531-b9f6-dd3c2cf5310a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a611dc2-2443-40bb-9b78-ff7721a1f678"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9500325322151184, 0.8170999884605408]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#Evaluate here\n",
        "\n",
        "model.evaluate(x_test, y_test, verbose=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bda89dbd-078b-4ba1-9897-77a68195c1f1",
      "metadata": {
        "id": "bda89dbd-078b-4ba1-9897-77a68195c1f1"
      },
      "source": [
        "## Evaluating Predictions\n",
        "\n",
        "### Change the image_index to see its predictions for other images!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b094017d-13f9-4cac-9729-8ece35881cdb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "b094017d-13f9-4cac-9729-8ece35881cdb",
        "outputId": "21dfdd70-1429-426b-b41f-de6cb851415e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n",
            "Model prediction: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "image_index = 1204\n",
        "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
        "pred = model.predict(np.array( [x_test[image_index],] ))\n",
        "print(\"Model prediction:\",pred.argmax())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2899936c-6c1e-4e23-a634-21d64715ee78",
      "metadata": {
        "id": "2899936c-6c1e-4e23-a634-21d64715ee78"
      },
      "source": [
        "## Go back through the model code from the earlier sections. Modify the hyperparameters (things like the learning rate, activation function, number of epochs, number of nodes, etc).Try different dropout rates. Addidtionally, add the 'momentum' parameter to our SGD optimizer to see how that effects the preformance.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
